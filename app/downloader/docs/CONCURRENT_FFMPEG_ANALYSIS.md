# FFmpeg å¹¶å‘åˆå¹¶è§†é¢‘é—®é¢˜æ·±åº¦åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## é—®é¢˜æ¦‚è¿°

åœ¨å¤šçº¿ç¨‹è§†é¢‘ä¸‹è½½å’Œåˆå¹¶åœºæ™¯ä¸­ï¼Œåªæœ‰ç¬¬ä¸€ä¸ªè§†é¢‘èƒ½æˆåŠŸåˆå¹¶ï¼Œåç»­åˆå¹¶å¤±è´¥ã€‚è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„å¹¶å‘èµ„æºç«äº‰é—®é¢˜ã€‚

## æ ¹æœ¬åŸå› åˆ†æ

### 1. **æ–‡ä»¶é”å®šå†²çª**
```python
# é—®é¢˜ä»£ç ç¤ºä¾‹
def merge_files(self, file_list, output_file, temp_dir):
    list_file = os.path.join(temp_dir, 'file_list.txt')  # âš ï¸ å›ºå®šæ–‡ä»¶å
    # å¤šä¸ªå¹¶å‘ä»»åŠ¡ä½¿ç”¨ç›¸åŒçš„ä¸´æ—¶æ–‡ä»¶åï¼Œå¯¼è‡´å†²çª
```

**é—®é¢˜è¡¨ç°ï¼š**
- æ‰€æœ‰å¹¶å‘ä»»åŠ¡å…±äº«ç›¸åŒçš„ä¸´æ—¶æ–‡ä»¶å `file_list.txt`
- ç¬¬ä¸€ä¸ªä»»åŠ¡åˆ›å»ºæ–‡ä»¶åï¼Œç¬¬äºŒä¸ªä»»åŠ¡ä¼šè¦†ç›–å®ƒ
- FFmpeg è¯»å–æ—¶å¯èƒ½æ–‡ä»¶å†…å®¹ä¸å®Œæ•´æˆ–å·²è¢«åˆ é™¤

### 2. **ä¸´æ—¶ç›®å½•æ±¡æŸ“**
```python
# é—®é¢˜ä»£ç 
task_temp_dir = os.path.join(self.config.temp_dir, task.name)
# å¦‚æœå¤šä¸ªä»»åŠ¡ä½¿ç”¨ç›¸åŒåç§°ï¼Œä¼šå…±äº«ä¸´æ—¶ç›®å½•
```

**é—®é¢˜è¡¨ç°ï¼š**
- TS æ–‡ä»¶äº’ç›¸è¦†ç›–
- æ¸…ç†æ—¶è¯¯åˆ å…¶ä»–ä»»åŠ¡çš„æ–‡ä»¶
- æ–‡ä»¶åˆ—è¡¨æ··ä¹±

### 3. **FFmpeg è¿›ç¨‹èµ„æºç«äº‰**
```rust
// Rust æœåŠ¡ä¸­çš„é—®é¢˜
pub struct FFmpegService {
    semaphore: Arc<Semaphore>,  // é™åˆ¶å¹¶å‘æ•°ï¼Œä½†æœªéš”ç¦»å·¥ä½œç©ºé—´
}
```

**é—®é¢˜è¡¨ç°ï¼š**
- å¤šä¸ª FFmpeg è¿›ç¨‹åŒæ—¶è¯»å†™ç›¸åŒè·¯å¾„
- ç£ç›˜ I/O ç«äº‰å¯¼è‡´è¯»å–å¤±è´¥
- ä¸´æ—¶æ–‡ä»¶è¢«æå‰åˆ é™¤

### 4. **Python GIL ä¸çº¿ç¨‹å®‰å…¨**
```python
class StreamDownloadManager:
    def __init__(self):
        self.lock = threading.Lock()  # âš ï¸ åªä¿æŠ¤éƒ¨åˆ†æ“ä½œ
        self.file_merger = FileMerger()  # å…±äº«çŠ¶æ€
```

**é—®é¢˜è¡¨ç°ï¼š**
- `FileMerger` å®ä¾‹è¢«å…±äº«ï¼ŒçŠ¶æ€æ··ä¹±
- é™é»˜æ¨¡å¼æ ‡å¿—è¢«å¹¶å‘ä¿®æ”¹
- è¿›åº¦æ˜¾ç¤ºé”™ä¹±

## è§£å†³æ–¹æ¡ˆ

### 1. **å®Œå…¨éš”ç¦»çš„ä¸´æ—¶å·¥ä½œç©ºé—´**

```python
import os
import uuid
from pathlib import Path

class IsolatedTaskWorkspace:
    """ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºå®Œå…¨éš”ç¦»çš„å·¥ä½œç©ºé—´"""
    
    def __init__(self, base_temp_dir: str, task_name: str):
        # ä½¿ç”¨ UUID ç¡®ä¿ç»å¯¹å”¯ä¸€æ€§
        self.task_id = f"{task_name}_{uuid.uuid4().hex[:8]}"
        self.workspace = os.path.join(base_temp_dir, self.task_id)
        
        # åˆ›å»ºéš”ç¦»ç›®å½•
        os.makedirs(self.workspace, exist_ok=True)
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        self.file_list_path = os.path.join(self.workspace, f"file_list_{self.task_id}.txt")
        self.output_temp = os.path.join(self.workspace, f"output_{self.task_id}.mp4")
    
    def cleanup(self):
        """å®‰å…¨æ¸…ç†ï¼Œåªåˆ é™¤è‡ªå·±çš„æ–‡ä»¶"""
        try:
            if os.path.exists(self.workspace):
                import shutil
                shutil.rmtree(self.workspace)
        except Exception as e:
            print(f"æ¸…ç†å¤±è´¥: {e}")
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()
```

### 2. **çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶åˆå¹¶å™¨**

```python
import threading
import subprocess
from typing import List, Optional
import logging

class ThreadSafeFileMerger:
    """çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶åˆå¹¶å™¨ï¼Œæ¯ä¸ªå®ä¾‹å®Œå…¨ç‹¬ç«‹"""
    
    def __init__(self, task_id: str, logger: Optional[logging.Logger] = None):
        self.task_id = task_id
        self.logger = logger
        self._lock = threading.Lock()  # ä¿æŠ¤å®ä¾‹çŠ¶æ€
        self._stop_flag = False
        
    def merge_with_ffmpeg(
        self, 
        file_list: List[str], 
        output_file: str,
        workspace: IsolatedTaskWorkspace
    ) -> bool:
        """ä½¿ç”¨å®Œå…¨éš”ç¦»çš„ä¸´æ—¶æ–‡ä»¶è¿›è¡Œåˆå¹¶"""
        
        with self._lock:
            if self._stop_flag:
                return False
            
            try:
                # 1. åˆ›å»ºå”¯ä¸€çš„æ–‡ä»¶åˆ—è¡¨
                self._create_file_list(file_list, workspace.file_list_path)
                
                # 2. æ„å»º FFmpeg å‘½ä»¤
                cmd = [
                    'ffmpeg',
                    '-f', 'concat',
                    '-safe', '0',
                    '-i', workspace.file_list_path,
                    '-c', 'copy',
                    '-bsf:a', 'aac_adtstoasc',
                    '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                    output_file
                ]
                
                # 3. æ‰§è¡Œåˆå¹¶ï¼ˆä½¿ç”¨ç‹¬ç«‹è¿›ç¨‹ï¼‰
                result = subprocess.run(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
                    check=False
                )
                
                if result.returncode != 0:
                    stderr = result.stderr.decode('utf-8', errors='ignore')
                    if self.logger:
                        self.logger.error(f"FFmpeg åˆå¹¶å¤±è´¥: {stderr}")
                    return False
                
                # 4. éªŒè¯è¾“å‡ºæ–‡ä»¶
                if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:
                    if self.logger:
                        self.logger.error("è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                    return False
                
                return True
                
            except subprocess.TimeoutExpired:
                if self.logger:
                    self.logger.error("FFmpeg æ‰§è¡Œè¶…æ—¶")
                return False
            except Exception as e:
                if self.logger:
                    self.logger.error(f"åˆå¹¶å¼‚å¸¸: {e}")
                return False
    
    def _create_file_list(self, file_list: List[str], list_file_path: str):
        """åˆ›å»ºæ–‡ä»¶åˆ—è¡¨ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„"""
        with open(list_file_path, 'w', encoding='utf-8') as f:
            for file_path in file_list:
                abs_path = os.path.abspath(file_path)
                # è½¬ä¹‰è·¯å¾„ä¸­çš„ç‰¹æ®Šå­—ç¬¦
                escaped_path = abs_path.replace("'", "'\\''")
                f.write(f"file '{escaped_path}'\n")
    
    def stop(self):
        """åœæ­¢å½“å‰åˆå¹¶"""
        self._stop_flag = True
```

### 3. **å¢å¼ºçš„ä¸‹è½½ç®¡ç†å™¨**

```python
import os
import uuid
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict

class EnhancedDownloadManager:
    """å¢å¼ºçš„ä¸‹è½½ç®¡ç†å™¨ï¼Œæ”¯æŒå®Œå…¨éš”ç¦»çš„å¹¶å‘æ“ä½œ"""
    
    def __init__(self, config, logger=None):
        self.config = config
        self.logger = logger or logging.getLogger(__name__)
        self._stop_flag = False
        self._active_tasks = {}  # task_id -> workspace
        
    def download_task(self, task) -> bool:
        """ä¸‹è½½å•ä¸ªä»»åŠ¡ï¼Œä½¿ç”¨å®Œå…¨éš”ç¦»çš„å·¥ä½œç©ºé—´"""
        
        # 1. åˆ›å»ºéš”ç¦»å·¥ä½œç©ºé—´
        workspace = IsolatedTaskWorkspace(
            base_temp_dir=self.config.temp_dir,
            task_name=task.name
        )
        
        # è®°å½•æ´»è·ƒä»»åŠ¡
        task_id = workspace.task_id
        self._active_tasks[task_id] = workspace
        
        try:
            self.logger.info(f"å¼€å§‹ä»»åŠ¡ {task.name} (ID: {task_id})")
            
            # 2. è§£æ M3U8
            parser = M3U8Parser(verify_ssl=self.config.verify_ssl)
            ts_files, parse_info = parser.parse_m3u8(task.url, self.config.headers)
            
            if not ts_files:
                self.logger.error(f"ä»»åŠ¡ {task.name}: æœªæ‰¾åˆ°TSæ–‡ä»¶")
                return False
            
            # 3. ä¸‹è½½ TS æ–‡ä»¶åˆ°éš”ç¦»ç›®å½•
            downloaded_files = self._download_segments(
                ts_files, workspace.workspace, task.name
            )
            
            if not downloaded_files:
                self.logger.error(f"ä»»åŠ¡ {task.name}: ä¸‹è½½å¤±è´¥")
                return False
            
            # 4. åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(task.output_dir, exist_ok=True)
            output_file = os.path.join(task.output_dir, f"{task.name}.mp4")
            
            # 5. ä½¿ç”¨éš”ç¦»çš„åˆå¹¶å™¨
            merger = ThreadSafeFileMerger(task_id, self.logger)
            success = merger.merge_with_ffmpeg(
                downloaded_files,
                output_file,
                workspace
            )
            
            if success:
                self.logger.info(f"ä»»åŠ¡ {task.name} å®Œæˆ: {output_file}")
                return True
            else:
                self.logger.error(f"ä»»åŠ¡ {task.name} åˆå¹¶å¤±è´¥")
                return False
                
        except Exception as e:
            self.logger.error(f"ä»»åŠ¡ {task.name} å¼‚å¸¸: {e}")
            return False
        finally:
            # 6. æ¸…ç†éš”ç¦»ç©ºé—´
            workspace.cleanup()
            if task_id in self._active_tasks:
                del self._active_tasks[task_id]
    
    def _download_segments(self, ts_files: List[str], temp_dir: str, task_name: str) -> List[str]:
        """ä¸‹è½½æ‰€æœ‰ TS ç‰‡æ®µï¼Œè¿”å›æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨"""
        local_files = []
        
        with ThreadPoolExecutor(max_workers=self.config.num_threads) as executor:
            futures = {}
            
            for i, url in enumerate(ts_files):
                if self._stop_flag:
                    break
                
                filename = f"segment_{i:05d}.ts"
                filepath = os.path.join(temp_dir, filename)
                
                future = executor.submit(
                    self._download_single_segment,
                    url,
                    filepath,
                    task_name
                )
                futures[future] = filepath
            
            for future in as_completed(futures):
                filepath = futures[future]
                try:
                    success = future.result()
                    if success:
                        local_files.append(filepath)
                except Exception as e:
                    self.logger.error(f"ä¸‹è½½ç‰‡æ®µå¤±è´¥ {filepath}: {e}")
        
        # æŒ‰æ–‡ä»¶åæ’åº
        return sorted(local_files)
    
    def _download_single_segment(self, url: str, filepath: str, task_name: str) -> bool:
        """ä¸‹è½½å•ä¸ªç‰‡æ®µ"""
        if os.path.exists(filepath):
            return True
        
        try:
            response = self.config.session.get(
                url,
                timeout=(self.config.connect_timeout, self.config.read_timeout),
                stream=True
            )
            response.raise_for_status()
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=self.config.chunk_size):
                    if self._stop_flag:
                        return False
                    if chunk:
                        f.write(chunk)
            
            return True
        except Exception as e:
            self.logger.error(f"ä¸‹è½½å¤±è´¥ {url}: {e}")
            if os.path.exists(filepath):
                os.remove(filepath)
            return False
    
    def stop(self):
        """åœæ­¢æ‰€æœ‰ä»»åŠ¡"""
        self._stop_flag = True
        # æ¸…ç†æ‰€æœ‰æ´»è·ƒçš„å·¥ä½œç©ºé—´
        for workspace in self._active_tasks.values():
            workspace.cleanup()
```

### 4. **Rust æœåŠ¡å±‚æ”¹è¿›**

```rust
//! æ”¹è¿›çš„ FFmpeg æœåŠ¡ï¼Œæ”¯æŒå·¥ä½œç©ºé—´éš”ç¦»

use std::path::{Path, PathBuf};
use std::process::Command;
use std::sync::Arc;
use tokio::sync::Semaphore;
use uuid::Uuid;

/// éš”ç¦»çš„å·¥ä½œç©ºé—´
pub struct IsolatedWorkspace {
    pub id: String,
    pub path: PathBuf,
    pub file_list_path: PathBuf,
}

impl IsolatedWorkspace {
    pub fn new(base_dir: &Path, task_name: &str) -> Self {
        let id = format!("{}_{}", task_name, Uuid::new_v4().as_simple().to_string()[..8]);
        let path = base_dir.join(&id);
        let file_list_path = path.join(format!("file_list_{}.txt", id));
        
        // åˆ›å»ºç›®å½•
        std::fs::create_dir_all(&path).ok();
        
        Self {
            id,
            path,
            file_list_path,
        }
    }
    
    pub fn cleanup(&self) {
        if self.path.exists() {
            let _ = std::fs::remove_dir_all(&self.path);
        }
    }
}

/// æ”¹è¿›çš„ FFmpeg æœåŠ¡
pub struct FFmpegService {
    config: FFmpegConfig,
    semaphore: Arc<Semaphore>,
    base_workspace: PathBuf,
}

impl FFmpegService {
    pub fn new(config: FFmpegConfig, base_workspace: PathBuf) -> Self {
        let semaphore = Arc::new(Semaphore::new(config.max_concurrent));
        
        // ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        std::fs::create_dir_all(&base_workspace).ok();
        
        Self {
            config,
            semaphore,
            base_workspace,
        }
    }
    
    /// åˆå¹¶ M3U8 åˆ° MP4ï¼Œä½¿ç”¨éš”ç¦»å·¥ä½œç©ºé—´
    pub async fn merge_m3u8_isolated(
        &self,
        m3u8_path: &Path,
        output_path: &Path,
        task_name: &str,
    ) -> Result<PathBuf, String> {
        let _permit = self.semaphore.acquire().await.unwrap();
        
        // åˆ›å»ºéš”ç¦»å·¥ä½œç©ºé—´
        let workspace = IsolatedWorkspace::new(&self.base_workspace, task_name);
        
        // åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
        let file_list_content = format!("file '{}'\n", m3u8_path.display());
        std::fs::write(&workspace.file_list_path, file_list_content)
            .map_err(|e| format!("æ— æ³•åˆ›å»ºæ–‡ä»¶åˆ—è¡¨: {}", e))?;
        
        // æ‰§è¡Œ FFmpeg
        let output = Command::new("ffmpeg")
            .args([
                "-f", "concat",
                "-safe", "0",
                "-i", workspace.file_list_path.to_string_lossy().as_ref(),
                "-c", "copy",
                "-bsf:a", "aac_adtstoasc",
                "-y",
                output_path.to_string_lossy().as_ref(),
            ])
            .output()
            .map_err(|e| format!("FFmpeg æ‰§è¡Œå¤±è´¥: {}", e))?;
        
        // æ¸…ç†å·¥ä½œç©ºé—´
        workspace.cleanup();
        
        if output.status.success() && output_path.exists() {
            Ok(output_path.to_path_buf())
        } else {
            let stderr = String::from_utf8_lossy(&output.stderr);
            Err(format!("åˆå¹¶å¤±è´¥: {}", stderr))
        }
    }
}
```

### 5. **é…ç½®æœ€ä½³å®è·µ**

```python
# config.py å¢å¼ºç‰ˆ

class DownloadConfig:
    def __init__(self):
        # å¹¶å‘æ§åˆ¶
        self.max_concurrent_downloads = 3  # ä¸‹è½½å¹¶å‘
        self.max_concurrent_merges = 2     # åˆå¹¶å¹¶å‘ï¼ˆé€šå¸¸æ›´å°‘ï¼‰
        
        # éš”ç¦»é…ç½®
        self.use_isolated_workspaces = True
        self.workspace_base = os.path.join(os.tempdir(), "video_downloader")
        
        # è¶…æ—¶é…ç½®
        self.download_timeout = 300       # 5åˆ†é’Ÿ
        self.merge_timeout = 600          # 10åˆ†é’Ÿ
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 5
        
        # èµ„æºæ¸…ç†
        self.auto_cleanup = True
        self.cleanup_delay = 60           # å®Œæˆå60ç§’æ¸…ç†
```

## å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹

```python
import logging
from concurrent.futures import ThreadPoolExecutor

def main():
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # é…ç½®
    config = DownloadConfig()
    config.max_concurrent_downloads = 3
    config.max_concurrent_merges = 2
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = EnhancedDownloadManager(config)
    
    # ä»»åŠ¡åˆ—è¡¨
    tasks = [
        DownloadTask("video1", "https://example.com/video1.m3u8", "/output/video1"),
        DownloadTask("video2", "https://example.com/video2.m3u8", "/output/video2"),
        DownloadTask("video3", "https://example.com/video3.m3u8", "/output/video3"),
    ]
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ§åˆ¶å¹¶å‘
    results = {}
    with ThreadPoolExecutor(max_workers=config.max_concurrent_downloads) as executor:
        futures = {executor.submit(manager.download_task, task): task.name for task in tasks}
        
        for future in as_completed(futures):
            task_name = futures[future]
            try:
                success = future.result()
                results[task_name] = success
                print(f"ä»»åŠ¡ {task_name}: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            except Exception as e:
                results[task_name] = False
                print(f"ä»»åŠ¡ {task_name} å¼‚å¸¸: {e}")
    
    # æ€»ç»“
    success_count = sum(1 for v in results.values() if v)
    print(f"\nå®Œæˆ: {success_count}/{len(tasks)} æˆåŠŸ")
    
    return all(results.values())

if __name__ == "__main__":
    main()
```

## å…³é”®è¦ç‚¹æ€»ç»“

### âœ… å¿…é¡»åšçš„
1. **å®Œå…¨éš”ç¦»å·¥ä½œç©ºé—´**ï¼šæ¯ä¸ªä»»åŠ¡ä½¿ç”¨å”¯ä¸€ä¸´æ—¶ç›®å½•
2. **å”¯ä¸€æ–‡ä»¶å**ï¼šé¿å…ä»»ä½•æ–‡ä»¶åå†²çª
3. **çº¿ç¨‹å®‰å…¨**ï¼šæ¯ä¸ªåˆå¹¶å™¨å®ä¾‹ç‹¬ç«‹ï¼Œä¸å…±äº«çŠ¶æ€
4. **è¶…æ—¶æ§åˆ¶**ï¼šé˜²æ­¢ FFmpeg æŒ‚èµ·
5. **æ¸…ç†æœºåˆ¶**ï¼šç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«æ­£ç¡®æ¸…ç†

### âŒ é¿å…çš„
1. å…±äº«ä¸´æ—¶æ–‡ä»¶æˆ–ç›®å½•
2. å…±äº«å¯å˜çŠ¶æ€
3. ä½¿ç”¨å›ºå®šæ–‡ä»¶å
4. ä¸æ¸…ç†ä¸´æ—¶æ–‡ä»¶
5. å¿½ç•¥é”™è¯¯å¤„ç†

### ğŸ”§ è°ƒè¯•æŠ€å·§
```python
# æ·»åŠ è¯¦ç»†æ—¥å¿—
def merge_with_debug(...):
    print(f"[{task_id}] å¼€å§‹åˆå¹¶")
    print(f"[{task_id}] æ–‡ä»¶åˆ—è¡¨: {file_list}")
    print(f"[{task_id}] å·¥ä½œç©ºé—´: {workspace.workspace}")
    print(f"[{task_id}] è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # æ‰§è¡Œå‰æ£€æŸ¥
    for f in file_list:
        if not os.path.exists(f):
            print(f"[{task_id}] é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {f}")
            return False
    
    # æ‰§è¡Œ FFmpeg...
```

è¿™ä¸ªè§£å†³æ–¹æ¡ˆç¡®ä¿äº†æ¯ä¸ªå¹¶å‘ä»»åŠ¡çš„å®Œå…¨éš”ç¦»ï¼Œæ¶ˆé™¤äº†èµ„æºç«äº‰ï¼Œæ˜¯ç”Ÿäº§ç¯å¢ƒå°±ç»ªçš„å®ç°ã€‚