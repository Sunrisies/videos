"""
é«˜çº§ä¸‹è½½å™¨æ¨¡å—
æ”¯æŒæµå¼ä¸‹è½½ã€JSONé…ç½®æ–‡ä»¶ã€å¤šä»»åŠ¡ç®¡ç†ã€åŠ å¯†M3U8è§£å¯†
"""

import os

import threading
import signal
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional
from tqdm import tqdm

from .config import DownloadConfig
from .download import DownloadTask
from .json_loader import JSONTaskLoader
from .merge_files import FileMerger
from .parser import M3U8Parser
from .crypto import EncryptionInfo, KeyManager, AESDecryptor, CryptoHelper
from .progress import MultiTaskProgress, SegmentProgressTracker
from .utils import (
    RetryHandler, setup_logger, create_session, extract_filename_from_url,
    disable_console_logging, enable_console_logging, check_ts_header, extract_filename
)


class StreamDownloadManager:
    """æµå¼ä¸‹è½½ç®¡ç†å™¨ - æ”¯æŒå®æ—¶è¿›åº¦æ›´æ–°ã€é¡ºåºä¸‹è½½å’ŒåŠ å¯†è§£å¯†"""

    def __init__(self, config: DownloadConfig = None):
        self.config = config or DownloadConfig()
        # ä½¿ç”¨ utils.py ä¸­çš„ create_session å‡½æ•°
        self.session = create_session(
            self.config.verify_ssl, self.config.headers)

        # çŠ¶æ€ç®¡ç†
        self.lock = threading.Lock()

        # è¾“å‡ºæ§åˆ¶
        self._quiet_mode = True  # é™é»˜æ¨¡å¼ï¼Œç”¨äºå¹¶å‘ä¸‹è½½æ—¶å‡å°‘è¾“å‡º
        self._output_lock = threading.Lock()  # è¾“å‡ºé”ï¼Œé˜²æ­¢å¹¶å‘è¾“å‡ºæ··ä¹±

        # å¤šä»»åŠ¡è¿›åº¦ç®¡ç†å™¨
        self._progress_manager: Optional[MultiTaskProgress] = None
        self._segment_tracker: Optional[SegmentProgressTracker] = None

        # æ—¥å¿—é…ç½®
        self.logger = None
        if self.config.enable_logging:
            # ä½¿ç”¨ utils.py ä¸­çš„ setup_logger å‡½æ•°
            self.logger = setup_logger(__name__)

        # é‡è¯•å¤„ç†å™¨ - ä½¿ç”¨ utils.py ä¸­çš„ RetryHandler
        self.retry_handler = RetryHandler(
            max_retries=self.config.max_retries,
            retry_delay=self.config.retry_delay
        )
        # å½“å‰æ€»è¿›åº¦
        self._total_progress = 0
        # ä¸€å…±å¤šå°‘ä¸ªä»»åŠ¡
        self._total_tasks = 0
        # åŠ å¯†ç›¸å…³ç»„ä»¶
        self._decryptor: Optional[AESDecryptor] = None
        self._media_sequence: int = 0

        # åˆå§‹åŒ–åŠ å¯†ç»„ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config.auto_decrypt and CryptoHelper.is_crypto_available():
            key_manager = KeyManager(
                cache_dir=self.config.key_cache_dir,
                cache_ttl=self.config.key_cache_ttl
            )
            self._decryptor = AESDecryptor(key_manager)

        # æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        self.file_merger = FileMerger(
            config=self.config,
            logger=self.logger,
            quiet_mode=self._quiet_mode
        )
        # ===== æ–°å¢ï¼šåˆå¹¶ä¸“ç”¨çº¿ç¨‹æ±  =====
        self._merge_pool = ThreadPoolExecutor(max_workers=10)
        # åˆå¹¶ä»»åŠ¡
        self._merge_task = []
        # ============================

    def _safe_print(self, message: str, end: str = "\n", flush: bool = False, force: bool = True):
        """
        çº¿ç¨‹å®‰å…¨çš„æ‰“å°å‡½æ•°

        Args:
            message: è¦æ‰“å°çš„æ¶ˆæ¯
            end: ç»“å°¾å­—ç¬¦
            flush: æ˜¯å¦ç«‹å³åˆ·æ–°
            force: æ˜¯å¦å¼ºåˆ¶æ‰“å°ï¼ˆå¿½ç•¥é™é»˜æ¨¡å¼ï¼‰
        """
        if self._quiet_mode and not force:
            return
        with self._output_lock:
            print(message, end=end, flush=flush)

    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†"""
        if self.logger:
            self.logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢ä¸‹è½½...")

    def merge_files(self, file_list: List[str], output_file: str, temp_dir: str) -> bool:
        """åˆå¹¶æ–‡ä»¶ - ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºç‹¬ç«‹çš„FileMergerå®ä¾‹"""
        # é¦–å…ˆéªŒè¯æ‰€æœ‰æ–‡ä»¶éƒ½å·²ä¸‹è½½å¹¶å®Œæ•´
        all_files_exist = True
        for url in file_list:
            filename = os.path.basename(url.split('?')[0])
            filepath = os.path.join(temp_dir, filename)
            if not os.path.exists(filepath):
                print(f"âŒ ç¼ºå¤±æ–‡ä»¶: {filepath}")
                if self.logger:
                    self.logger.error(f"ç¼ºå¤±æ–‡ä»¶: {filepath}")
                all_files_exist = False
            else:
                # éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆTSæ ¼å¼
                if not check_ts_header(filepath):
                    print(f"âŒ æ— æ•ˆæ–‡ä»¶: {filepath}")
                    if self.logger:
                        self.logger.error(f"æ— æ•ˆæ–‡ä»¶: {filepath}")
                    all_files_exist = False

        if not all_files_exist:
            print(f"âŒ æ— æ³•åˆå¹¶ - å­˜åœ¨ç¼ºå¤±æˆ–æ— æ•ˆçš„TSæ–‡ä»¶")
            if self.logger:
                self.logger.error(f"æ— æ³•åˆå¹¶ - å­˜åœ¨ç¼ºå¤±æˆ–æ— æ•ˆçš„TSæ–‡ä»¶")
            return False

        if self.logger:
            self.logger.info(
                f"åˆå¹¶æ–‡ä»¶: {output_file},temp_dir: {temp_dir}")
        merger = FileMerger(
            config=self.config,
            logger=self.logger,
            quiet_mode=self._quiet_mode
        )
        return merger.merge_files(file_list, output_file, temp_dir)

    def download_file_stream(self, url: str, save_path: str, filename: str, task_name: str, segment_index: int = 0,
                             enc_info: Optional[EncryptionInfo] = None) -> bool:
        """
        ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼ˆæµå¼ï¼Œå®æ—¶æ›´æ–°è¿›åº¦ï¼‰

        Args:
            url: æ–‡ä»¶URL
            save_path: ä¿å­˜è·¯å¾„
            filename: æ–‡ä»¶å
            task_name: ä»»åŠ¡åç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            segment_index: ç‰‡æ®µç´¢å¼•ï¼ˆç”¨äº IV è®¡ç®—ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """

        filepath = os.path.join(save_path, filename)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(filepath):
            # éªŒè¯å·²å­˜åœ¨çš„æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
            if check_ts_header(filepath):
                print(f"âœ“ {task_name}: {filename} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                return True
            else:
                # æ–‡ä»¶å­˜åœ¨ä½†æ— æ•ˆï¼Œåˆ é™¤å¹¶é‡æ–°ä¸‹è½½
                try:
                    os.remove(filepath)
                except:
                    pass

        try:
            # ä½¿ç”¨é‡è¯•æœºåˆ¶ä¸‹è½½
            def _download():
                response = self.session.get(
                    url,
                    timeout=(self.config.connect_timeout,
                             self.config.read_timeout),
                    stream=True
                )
                response.raise_for_status()

                # è·å–æ–‡ä»¶å¤§å°
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                chunks = []

                # åˆ†å—ä¸‹è½½ï¼ˆé™é»˜æ¨¡å¼ä¸‹ä¸æ˜¾ç¤ºå®æ—¶è¿›åº¦ï¼‰
                for chunk in response.iter_content(chunk_size=self.config.chunk_size):
                    if chunk:
                        chunks.append(chunk)
                        downloaded_size += len(chunk)

                # åˆå¹¶æ•°æ®
                data = b''.join(chunks)

                # å¦‚æœå¯ç”¨è§£å¯†ä¸”æœ‰åŠ å¯†ä¿¡æ¯ï¼Œè§£å¯†æ•°æ®
                if self._should_decrypt(enc_info):
                    # è¯»å–å¯†é’¥ç¼“å­˜æ–‡ä»¶
                    cache_path = self._decryptor.key_manager.get_cache_path(task_name)

                    if os.path.exists(cache_path):
                        try:
                            # è¯»å–å¯†é’¥å†…å®¹
                            with open(cache_path, 'rb') as f:
                                key_content = f.read()

                            if self.logger:
                                self.logger.debug(
                                    f"ä»ç¼“å­˜è¯»å–å¯†é’¥: {cache_path}, ç‰‡æ®µç´¢å¼•: {segment_index}, "
                                    f"å¯†é’¥é•¿åº¦: {len(key_content)}"
                                )
                            # è§£å¯†æ•°æ®ï¼ˆå¦‚æœè§£å¯†å¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸ï¼‰
                            data = self._decrypt_segment(key_content, data, segment_index, enc_info)
                            # è§£å¯†åç«‹å³éªŒè¯æ•°æ®æ˜¯å¦æœ‰æ•ˆï¼ˆæ£€æŸ¥TSå¤´éƒ¨ï¼‰
                            if len(data) < 4 or data[0] != 0x47:
                                print(
                                    f"è§£å¯†åçš„æ•°æ®ä¸æ˜¯æœ‰æ•ˆçš„TSæ ¼å¼: ç¬¬ä¸€ä¸ªå­—èŠ‚=0x{data[0]:02X if len(data) > 0 else 0}")

                        except Exception as e:
                            error_msg = f"è§£å¯†å¤±è´¥: {e}, segment_index={segment_index}"
                            if self.logger:
                                self.logger.error(f"{task_name}: {filename} - {error_msg}")
                            self._safe_print(f"âŒ {task_name}: {filename} - {error_msg}")
                            return False
                    else:
                        error_msg = f"å¯†é’¥ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_path}"
                        if self.logger:
                            self.logger.error(f"{task_name}: {filename} - {error_msg}")
                        self._safe_print(f"âŒ {task_name}: {filename} - {error_msg}")
                        return False
                else:
                    print(f"ä¸è¿›è¡Œè§£å¯†çš„æ–‡ä»¶: {task_name}: {filename}")
                
                # å†™å…¥æ–‡ä»¶å¹¶ç¡®ä¿æ•°æ®å®Œå…¨å†™å…¥ç£ç›˜
                with open(filepath, 'wb') as f:
                    f.write(data)
                    # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒºï¼Œç¡®ä¿æ•°æ®å†™å…¥ç£ç›˜
                    f.flush()
                    os.fsync(f.fileno())

                # éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆTSæ ¼å¼ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
                if not check_ts_header(filepath):
                    # å¦‚æœæ–‡ä»¶æ— æ•ˆï¼Œåˆ é™¤å®ƒ
                    try:
                        os.remove(filepath)
                    except:
                        pass

                    error_msg = f"æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„TSæ ¼å¼ï¼ˆå¯èƒ½è§£å¯†å¤±è´¥ï¼‰"
                    if self.logger:
                        self.logger.error(f"{task_name}: {filename} - {error_msg}")
                    self._safe_print(f"âŒ {task_name}: {filename} - {error_msg}")

                    return False

                return True

            result = self.retry_handler.execute_with_retry(_download)

            if result:
                if self.logger:
                    self.logger.info(f"{task_name}: {filename} ä¸‹è½½æˆåŠŸ")

            return result

        except Exception as e:
            self._safe_print(f"âœ— {task_name}: {filename} ä¸‹è½½å¤±è´¥ - {e}")
            if self.logger:
                self.logger.error(f"{task_name}: {filename} ä¸‹è½½å¤±è´¥ - {e}")
            return False

    def _should_decrypt(self, enc_info: Optional[EncryptionInfo] = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è§£å¯†"""
        return (
                self.config.auto_decrypt and
                self._decryptor is not None and
                enc_info
        )

    def _decrypt_segment(self, key: bytes, data: bytes, segment_index: int,
                         enc_info: Optional[EncryptionInfo] = None) -> bytes:
        """
        è§£å¯†ç‰‡æ®µæ•°æ®

        Args:
            data: åŠ å¯†çš„ç‰‡æ®µæ•°æ®
            segment_index: ç‰‡æ®µç´¢å¼•

        Returns:
            bytes: è§£å¯†åçš„æ•°æ®
        """
        if not self._should_decrypt(enc_info):
            return data

        try:
            # è®¡ç®—å®é™…åºåˆ—å·
            sequence_number = self._media_sequence + segment_index
            custom_iv = self.config.get_custom_iv()
            if custom_iv:
                iv = custom_iv
            elif enc_info.iv is not None:
                iv = enc_info.iv
            else:
                # æ²¡æœ‰æ˜¾å¼IVï¼Œä¼ é€’Noneè®©decryptæ–¹æ³•æ ¹æ®sequence_numberç”Ÿæˆ
                iv = None

            if self.logger:
                self.logger.info(
                    f"è§£å¯†ç‰‡æ®µ {segment_index}: sequence_number={sequence_number}, ")
            return self._decryptor.decrypt(data, key, iv=iv, sequence_number=sequence_number)

        except Exception as e:
            error_msg = f"è§£å¯†å¤±è´¥: {e}, segment_index={segment_index}, sequence_number={sequence_number}"
            if self.logger:
                self.logger.error(error_msg)
            # è§£å¯†å¤±è´¥ä¸åº”è¯¥è¿”å›åŸå§‹æ•°æ®ï¼Œåº”è¯¥æŠ›å‡ºå¼‚å¸¸
            raise ValueError(error_msg)

    def _build_encryption_info(self,
                               parse_info: Dict,
                               task: DownloadTask) -> Optional[EncryptionInfo]:
        """
        æ ¹æ® M3U8 è§£æç»“æœï¼Œæ„é€ å½“å‰ä»»åŠ¡ä¸“ç”¨çš„åŠ å¯†ä¿¡æ¯å¯¹è±¡
        è¿”å› None è¡¨ç¤ºæ— åŠ å¯†
        """
        if not self.config.auto_decrypt:
            return None

        if not CryptoHelper.is_crypto_available():
            self._safe_print("âš ï¸ åŠ å¯†åº“æœªå®‰è£…ï¼Œæ— æ³•è§£å¯†ã€‚è¯·è¿è¡Œ: pip install pycryptodome")
            return None

        encryption_data = parse_info.get('encryption')
        if not encryption_data:
            return None

        enc_info = EncryptionInfo(
            method=encryption_data.get('method', 'NONE'),
            uri=encryption_data.get('uri'),
            iv=bytes.fromhex(encryption_data['iv']) if encryption_data.get('iv') else None,
            key_format=encryption_data.get('key_format', 'identity'),
            key_format_versions=encryption_data.get('key_format_versions', '')
        )

        # é¢„åŠ è½½å¯†é’¥ï¼ˆä»ç„¶ç”¨å…¬å…±çš„ _decryptorï¼Œä½† key ä¼šæŒ‰ URI ç¼“å­˜ï¼Œä¸ä¼šä¸²ï¼‰
        if enc_info.is_encrypted() and enc_info.uri and self._decryptor:
            ok = self._decryptor.load_key_from_uri(
                enc_info.uri,
                task.name,  # ç”¨ä»»åŠ¡ååšç¼“å­˜ç©ºé—´éš”ç¦»
                verify_ssl=self.config.verify_ssl,
                headers=self.config.headers
            )
            if ok:
                print(f"ğŸ” ä»»åŠ¡ã€{task.name}ã€‘å·²åŠ è½½è§£å¯†å¯†é’¥")
            else:
                print(f"âš ï¸ ä»»åŠ¡ã€{task.name}ã€‘æ— æ³•åŠ è½½è§£å¯†å¯†é’¥: {enc_info.uri}")

        return enc_info

    def download_batch_tasks(self, tasks: List[DownloadTask], max_concurrent: int = 6) -> Dict[str, bool]:
        """
        æ‰¹é‡ä¸‹è½½å¤šä¸ªä»»åŠ¡ï¼ˆæ”¯æŒå¯æ§å¹¶å‘ï¼Œå¸¦å¤šä»»åŠ¡è¿›åº¦æ¡ï¼‰

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•° (é»˜è®¤6ä¸ª)

        Returns:
            Dict[str, bool]: æ¯ä¸ªä»»åŠ¡çš„æ‰§è¡Œç»“æœ
        """
        results = {}
        self._total_tasks = len(tasks)

        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡")
        print(f"ğŸ“Š æœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
        print(f"{'=' * 60}\n")

        # åˆ›å»ºå¤šä»»åŠ¡è¿›åº¦ç®¡ç†å™¨
        self._progress_manager = MultiTaskProgress(
            max_display_tasks=max_concurrent)
        self._quiet_mode = True  # å¯ç”¨é™é»˜æ¨¡å¼ï¼Œä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤º

        # ç¦ç”¨æ§åˆ¶å°æ—¥å¿—è¾“å‡ºï¼Œé¿å…å¹²æ‰°è¿›åº¦æ¡
        if self.logger:
            disable_console_logging(self.logger)

        try:
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡ï¼Œé™åˆ¶å¹¶å‘æ•°
            with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                futures = {}
                for task in tasks:
                    future = executor.submit(
                        self._download_task_with_progress, task)
                    futures[future] = task.name

                # æ”¶é›†ç»“æœ
                for future in as_completed(futures):
                    task_name = futures[future]
                    try:
                        result = future.result()
                        results[task_name] = result
                    except Exception as e:
                        results[task_name] = False
                        if self.logger:
                            self.logger.error(f"ä»»åŠ¡ {task_name} å¼‚å¸¸: {e}")

        finally:
            # æ¢å¤éé™é»˜æ¨¡å¼
            self._quiet_mode = True

            # æ¢å¤æ§åˆ¶å°æ—¥å¿—è¾“å‡º
            if self.logger:
                enable_console_logging(self.logger)

            # ç­‰å¾…æ‰€æœ‰åˆå¹¶ä»»åŠ¡å®Œæˆ
            if self._merge_task:
                print(f"\nâ³ ç­‰å¾…åˆå¹¶ä»»åŠ¡å®Œæˆ...")
                for future in self._merge_task:
                    try:
                        future.result()
                    except Exception as e:
                        if self.logger:
                            self.logger.error(f"åˆå¹¶ä»»åŠ¡å¼‚å¸¸: {e}")
                self._merge_task = []

            # æ‰“å°æ±‡æ€»ä¿¡æ¯
            if self._progress_manager:
                print()  # ç©ºè¡Œåˆ†éš”è¿›åº¦æ¡å’Œæ±‡æ€»
                self._progress_manager.print_summary()
                self._progress_manager.clear()
                self._progress_manager = None

            # æ¸…ç†å¯†é’¥ç¼“å­˜
            if self.config.clean_key_cache and self._decryptor:
                self._decryptor.key_manager.clear_cache()
                self._cleanup_key_cache_dir()

        return results

    def _cleanup_key_cache_dir(self):
        """æ¸…ç†å¯†é’¥ç¼“å­˜ç›®å½•"""
        try:
            cache_dir = self.config.key_cache_dir
            if os.path.exists(cache_dir):
                import shutil
                shutil.rmtree(cache_dir)
                if self.logger:
                    self.logger.info(f"å·²æ¸…ç†å¯†é’¥ç¼“å­˜ç›®å½•: {cache_dir}")
        except Exception as e:
            if self.logger:
                self.logger.warning(f"æ¸…ç†å¯†é’¥ç¼“å­˜ç›®å½•å¤±è´¥: {e}")

    def _download_task_with_progress(self, task: DownloadTask) -> bool:
        """
        å¸¦è¿›åº¦æ¡çš„ä»»åŠ¡ä¸‹è½½ï¼ˆç”¨äºæ‰¹é‡ä¸‹è½½æ¨¡å¼ï¼‰

        Args:
            task: ä¸‹è½½ä»»åŠ¡

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        # ä¸ºå½“å‰ä»»åŠ¡åˆ›å»ºä¸´æ—¶å­ç›®å½•
        task_temp_dir = os.path.join(self.config.temp_dir, task.name)
        tracker: Optional[SegmentProgressTracker] = None
        self._total_progress += 1
        self.logger.info(f"ä»»åŠ¡ {self._total_progress}/{self._total_tasks} å¼€å§‹å¤„ç†")
        
        # æ³¨å†Œä»»åŠ¡åˆ°è¿›åº¦ç®¡ç†å™¨ï¼ˆå³ä½¿è§£æå¤±è´¥ä¹Ÿè¦æ³¨å†Œï¼‰
        if self._progress_manager:
            self._progress_manager.register_task(task.name, 0)  # å…ˆæ³¨å†Œï¼Œæ€»æ•°ä¸º0
            tracker = SegmentProgressTracker(
                task.name, 0, self._progress_manager)
            tracker.start()
        
        try:
            # è§£æM3U8
            parser = M3U8Parser(verify_ssl=self.config.verify_ssl)
            ts_files, parse_info = parser.parse_m3u8(
                task.url, self.config.headers)

            if not ts_files:
                # è§£æå¤±è´¥ï¼Œæ ‡è®°ä»»åŠ¡å¤±è´¥
                if tracker:
                    tracker.finish(success=False, message="M3U8è§£æå¤±è´¥")
                return False
            total_segments = len(ts_files)

            # æ›´æ–°ä»»åŠ¡æ€»æ•°
            if tracker:
                tracker.total_segments = total_segments
                if self._progress_manager:
                    task_progress = self._progress_manager.get_task(task.name)
                    if task_progress:
                        task_progress.total_segments = total_segments

            # è®¾ç½®åŠ å¯†ä¿¡æ¯
            enc_info = self._build_encryption_info(parse_info, task)

            # åˆ›å»ºä¸´æ—¶ç›®å½•
            os.makedirs(task_temp_dir, exist_ok=True)

            # æ£€æŸ¥å·²ä¸‹è½½çš„æ–‡ä»¶
            downloaded = self.get_downloaded_files(task_temp_dir, ts_files)

            # æ›´æ–°å·²å®Œæˆçš„è¿›åº¦
            if downloaded and tracker:
                for _ in range(len(downloaded)):
                    tracker.on_segment_complete(success=True)

            # ä¸‹è½½æœªå®Œæˆçš„æ–‡ä»¶ï¼ˆä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½ï¼‰
            remaining_urls = [url for url in ts_files if url not in downloaded]
            self.logger.info(f"  [{task.name}] å‰©ä½™æœªä¸‹è½½çš„æ–‡ä»¶: {len(remaining_urls)}")
            if len(remaining_urls)  == 0:
                self.logger.info(f"ä»»åŠ¡ {task.name} å·²å®Œæˆ,å¼€å§‹åˆå¹¶")
                os.makedirs(task.output_dir, exist_ok=True)
                output_file = os.path.join(task.output_dir, f"{task.name}.mp4")
                # ç›´æ¥åˆå¹¶
                self._merge_task.append(self._merge_pool.submit(self.merge_files, ts_files, output_file, task_temp_dir))

                return True

            # å»ºç«‹ URL -> åŸå§‹ç´¢å¼• çš„æ˜ å°„ï¼Œç¡®ä¿segment_indexæ­£ç¡®
            url_to_index_map = {url: i for i, url in enumerate(ts_files)}

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½
            with ThreadPoolExecutor(max_workers=self.config.num_threads) as executor:
                # åˆ›å»ºä¸‹è½½ä»»åŠ¡
                futures = {}
                for url in remaining_urls:
                    filename = extract_filename(url)
                    # ä»æ˜ å°„è¡¨ä¸­è·å–çœŸå®çš„ç´¢å¼•ï¼Œç¡®ä¿è§£å¯†æ—¶ä½¿ç”¨æ­£ç¡®çš„segment_index
                    segment_index = url_to_index_map.get(url, -1)
                    if segment_index == -1:
                        if self.logger:
                            self.logger.warning(f"æ— æ³•æ‰¾åˆ°URLçš„ç´¢å¼•: {url}")
                        continue

                    future = executor.submit(
                        self.download_file_stream,
                        url, task_temp_dir, filename, task.name, segment_index, enc_info
                    )
                    futures[future] = url

                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(futures):
                    url = futures[future]
                    filename = extract_filename(url)
                    try:
                        self.logger.info(f"ä»»åŠ¡ {task.name} ä¸‹è½½å®Œæˆ: {url}")
                        success = future.result()
                        if tracker:
                            tracker.on_segment_complete(
                                success=success, filename=filename)
                    except Exception as e:
                        if tracker:
                            tracker.on_segment_complete(
                                success=False, filename=filename)
                        if self.logger:
                            self.logger.error(f"ä¸‹è½½ç‰‡æ®µ {url} å¤±è´¥: {e}")

                    # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                    completed = len([f for f in futures if f.done()])
                    total_remaining = len(remaining_urls)
                    if completed % 10 == 0 or completed == total_remaining:
                        downloaded_now = self.get_downloaded_files(task_temp_dir, ts_files)
                        downloaded_count = len(downloaded_now)
                        missing_count = len(ts_files) - downloaded_count
                        if not self._quiet_mode:
                            print(
                                f"  [{task.name}] è¿›åº¦: {downloaded_count}/{len(ts_files)} å·²ä¸‹è½½, {missing_count} å‰©ä½™")

                # æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆåï¼Œæ£€æŸ¥å¹¶åˆå¹¶æ–‡ä»¶
                all_downloaded = self.get_downloaded_files(
                    task_temp_dir, ts_files, validate=True)
                missing_count = len(ts_files) - len(all_downloaded)
                os.makedirs(task.output_dir, exist_ok=True)
                output_file = os.path.join(task.output_dir, f"{task.name}.mp4")

                if missing_count > 0:
                    if not self._quiet_mode:
                        print(f"âš ï¸  æœ‰ {missing_count} ä¸ªæ–‡ä»¶æœªæˆåŠŸä¸‹è½½æˆ–æ— æ•ˆï¼Œå°è¯•é‡æ–°ä¸‹è½½...")
                    if self.logger:
                        self.logger.warning(f"ä»»åŠ¡ {task.name}: {missing_count} ä¸ªæ–‡ä»¶ç¼ºå¤±ï¼Œå¼€å§‹é‡è¯•ä¸‹è½½")

                    # é‡è¯•ä¸‹è½½æœªå®Œæˆçš„æ–‡ä»¶ï¼ˆæœ€å¤šé‡è¯•3æ¬¡ï¼‰
                    remaining_urls = [
                        url for url in ts_files if url not in all_downloaded]
                    max_retry_attempts = 3

                    for retry_attempt in range(max_retry_attempts):
                        retry_success_count = 0
                        for url in remaining_urls[:]:  # ä½¿ç”¨åˆ‡ç‰‡å¤åˆ¶ï¼Œé¿å…è¿­ä»£æ—¶ä¿®æ”¹
                            filename = extract_filename(url)
                            segment_index = ts_files.index(url)  # ä¿æŒåŸå§‹é¡ºåº
                            download_success = self.download_file_stream(
                                url, task_temp_dir, filename, task.name, segment_index, enc_info
                            )
                            if download_success:
                                all_downloaded.add(url)
                                remaining_urls.remove(url)
                                retry_success_count += 1

                        if not remaining_urls:
                            break  # æ‰€æœ‰æ–‡ä»¶éƒ½ä¸‹è½½æˆåŠŸäº†

                        if retry_attempt < max_retry_attempts - 1:
                            if not self._quiet_mode:
                                print(
                                    f"é‡è¯• {retry_attempt + 1}/{max_retry_attempts}: æˆåŠŸ {retry_success_count} ä¸ªï¼Œå‰©ä½™ {len(remaining_urls)} ä¸ª")

                    # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœè¿˜æœ‰æ–‡ä»¶ç¼ºå¤±æˆ–æ— æ•ˆï¼Œä¸å…è®¸åˆå¹¶
                    all_downloaded = self.get_downloaded_files(task_temp_dir, ts_files, validate=True)
                    missing_count = len(ts_files) - len(all_downloaded)

                    if missing_count > 0:
                        if tracker:
                            tracker.finish(success=False, message=f"{missing_count} ä¸ªæ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–æ— æ•ˆ")
                        if self.logger:
                            self.logger.error(
                                f"ä»»åŠ¡ {task.name}: {missing_count} ä¸ªæ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–æ— æ•ˆï¼Œæ— æ³•åˆå¹¶")
                        return False

                # éªŒè¯æ‰€æœ‰æ–‡ä»¶çš„æœ‰æ•ˆæ€§
                invalid_files = []
                for url in ts_files:
                    filename = extract_filename(url)
                    filepath = os.path.join(task_temp_dir, filename)
                    if not os.path.exists(filepath):
                        invalid_files.append(filename)
                    elif not check_ts_header(filepath):
                        invalid_files.append(filename)
                        if self.logger:
                            self.logger.warning(f"æ–‡ä»¶ {filename} ä¸æ˜¯æœ‰æ•ˆçš„TSæ ¼å¼")

                if invalid_files:
                    if tracker:
                        tracker.finish(success=False, message=f"{len(invalid_files)} ä¸ªæ— æ•ˆæ–‡ä»¶")
                    if self.logger:
                        self.logger.error(f"ä»»åŠ¡ {task.name}: æ— æ•ˆæ–‡ä»¶åˆ—è¡¨: {invalid_files[:10]}")
                    return False

                # æäº¤åˆå¹¶ä»»åŠ¡ï¼ˆåªæäº¤ä¸€æ¬¡ï¼‰
                if tracker:
                    tracker.on_merge_start()
                    self.logger.debug(f"[{task.name}] åˆå¹¶ä¸­...........")
                self._merge_task.append(self._merge_pool.submit(self.merge_files, ts_files, output_file, task_temp_dir))
        except Exception as e:
            if self.logger:
                self.logger.warning(f"ä¸‹è½½å¤±è´¥: {e}")
        return True

    def get_downloaded_files(self, save_dir: str, urls: List[str], validate: bool = False) -> set:
        """
        è·å–å·²ä¸‹è½½çš„æ–‡ä»¶é›†åˆ
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
            urls: URLåˆ—è¡¨
            validate: æ˜¯å¦éªŒè¯æ–‡ä»¶æœ‰æ•ˆæ€§ï¼ˆæ£€æŸ¥TSå¤´éƒ¨ï¼‰
        
        Returns:
            å·²ä¸‹è½½çš„æ–‡ä»¶URLé›†åˆ
        """
        downloaded = set()
        for url in urls:
            filename = extract_filename(url)
            filepath = os.path.join(save_dir, filename)
            if os.path.exists(filepath):
                # å¦‚æœå¯ç”¨éªŒè¯ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
                if validate:
                    if check_ts_header(filepath):
                        downloaded.add(url)
                else:
                    downloaded.add(url)
        return downloaded

    def cleanup_task_temp_dir(self, task_temp_dir: str):
        """æ¸…ç†ä»»åŠ¡ä¸´æ—¶ç›®å½•"""
        try:
            if os.path.exists(task_temp_dir):
                # åˆ é™¤æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
                for filename in os.listdir(task_temp_dir):
                    filepath = os.path.join(task_temp_dir, filename)
                    if os.path.isfile(filepath):
                        os.remove(filepath)
                # åˆ é™¤ç›®å½•
                os.rmdir(task_temp_dir)
        except Exception as e:
            if self.logger:
                self.logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")


class AdvancedM3U8Downloader:
    """é«˜çº§M3U8ä¸‹è½½å™¨ - æ”¯æŒJSONé…ç½®å’Œæµå¼ä¸‹è½½"""

    def __init__(self, config: DownloadConfig = None):
        self.config = config or DownloadConfig()
        self.manager = StreamDownloadManager(self.config)
        self.task_loader = JSONTaskLoader()

    def download_from_json(self, json_file: str, base_output_dir: str, max_concurrent: int = 3) -> bool:
        """
        ä»JSONæ–‡ä»¶ä¸‹è½½å¤šä¸ªä»»åŠ¡

        Args:
            json_file: JSONé…ç½®æ–‡ä»¶è·¯å¾„
            base_output_dir: åŸºç¡€è¾“å‡ºç›®å½•
            max_concurrent: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°

        Returns:
            bool: æ˜¯å¦æ‰€æœ‰ä»»åŠ¡æˆåŠŸ
        """
        try:
            # åŠ è½½ä»»åŠ¡
            tasks = self.task_loader.load_from_file(json_file, base_output_dir)

            if not tasks:
                print("âŒ JSONæ–‡ä»¶ä¸­æ²¡æœ‰ä»»åŠ¡")
                return False
            print(f"ğŸ“‹ åŠ è½½äº† {len(tasks)} ä¸ªä»»åŠ¡")

            # æ‰§è¡Œæ‰¹é‡ä¸‹è½½
            results = self.manager.download_batch_tasks(tasks, max_concurrent)

            # æ£€æŸ¥ç»“æœ
            success_count = sum(1 for v in results.values() if v)
            return success_count == len(tasks)

        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            if self.manager.logger:
                self.manager.logger.error(f"JSONä¸‹è½½æ‰§è¡Œå¤±è´¥: {e}")
            return False
